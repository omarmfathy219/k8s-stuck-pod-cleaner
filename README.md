# ğŸ§¹ k8s-stuck-pod-cleaner

A Kubernetes CronJob that automatically cleans up pods stuck in Terminating state.

![Architecture Diagram](docs/architecture.svg)

## ğŸš¨ Problem

In Kubernetes clusters, pods can sometimes get stuck in the Terminating state, especially when nodes become unhealthy. This can cause resource leaks, block deployments, and create critical situations in production environments.

## âœ… Solution

This project provides a simple yet effective solution: a Kubernetes CronJob that:
- ğŸ”„ Runs on a configurable schedule (default: every minute)
- ğŸ” Detects pods stuck in Terminating state
- â±ï¸ Force deletes them after a configurable time threshold (default: 3 minutes)
- ğŸ“ Creates Kubernetes events for audit and tracking

## âš™ï¸ How It Works

![Workflow Diagram](docs/workflow.png)

The stuck pod cleaner follows this process:

1. **ğŸ•’ Scheduled Execution**: The CronJob runs on a configurable schedule (default: every minute)

2. **ğŸ” Pod Discovery**: The job scans all pods across the cluster (or selected namespaces) to find those in the "Terminating" state

3. **â³ Time Analysis**: For each terminating pod, it calculates how long the pod has been in that state

4. **ğŸ§  Cleanup Decision**: Pods that have been stuck for longer than the threshold (default: 3 minutes) are force deleted

5. **ğŸ“Š Audit Trail**: Kubernetes events are created to maintain a record of which pods were force deleted

### ğŸ”§ Technical Implementation

The solution is implemented as a Kubernetes CronJob that runs a container with the kubectl tool. This approach requires minimal resources and dependencies.

#### Key Components:

- **â° CronJob**: Provides the scheduling mechanism
- **ğŸ”‘ ServiceAccount**: Provides the necessary permissions
- **ğŸ‘‘ ClusterRole/ClusterRoleBinding**: Grants permission to list/delete pods and create events
- **ğŸ’» Bash Script**: Contains the logic for identifying and cleaning up stuck pods

## ğŸ“¦ Installation

### Option 1: Apply YAML directly

```bash
kubectl apply -f https://raw.githubusercontent.com/omarmfathy219/k8s-stuck-pod-cleaner/main/stuck-pod-cleaner.yaml
```

### Option 2: Install using Helm

```bash
# Add the repository
helm repo add omarmfathy219 https://omarmfathy219.github.io/helm-charts/

# Install the chart
helm install stuck-pod-cleaner omarmfathy219/stuck-pod-cleaner

# Or install with custom values
helm install stuck-pod-cleaner omarmfathy219/stuck-pod-cleaner --set podDeletion.minTimeBeforeDeletion=5
```

## âš™ï¸ Configuration

### YAML Configuration

The default configuration:
- ğŸ• Runs every minute
- ğŸŒ Scans all namespaces
- â±ï¸ Force deletes pods that have been in Terminating state for more than 3 minutes

You can customize these settings by editing the YAML file before applying it.

### Helm Configuration

When using Helm, you can customize the installation using values:

| Parameter | Description | Default |
|-----------|-------------|---------|
| `namespace` | Namespace where the cleaner is deployed | `kube-system` |
| `namespaces.scanAll` | Whether to scan all namespaces | `true` |
| `namespaces.include` | List of namespaces to scan (if scanAll is false) | `[]` |
| `namespaces.exclude` | List of namespaces to exclude from scanning | `[]` |
| `cronJob.schedule` | CronJob schedule | `* * * * *` (every minute) |
| `podDeletion.minTimeBeforeDeletion` | Time threshold in minutes before force deletion | `3` |
| `podDeletion.createEvents` | Whether to create Kubernetes events | `true` |
| `resources.limits/requests` | Pod resource limits and requests | See values.yaml |

For a full list of configurable options, see the `values.yaml` file.

## ğŸ”’ Security Considerations

- ğŸ›¡ï¸ The solution follows least privilege principles, requesting only the permissions it needs
- ğŸ‘¤ The pod runs with a non-root user and a read-only filesystem when using Helm
- ğŸ“Š Resource limits prevent the cleaner from consuming excessive cluster resources

## ğŸ” Troubleshooting

If you're experiencing issues with the cleaner, here are some common troubleshooting steps:

1. Check the CronJob logs:
   ```
   kubectl logs -n kube-system -l app=stuck-pod-cleaner
   ```

2. Verify RBAC permissions:
   ```
   kubectl auth can-i delete pods --as=system:serviceaccount:kube-system:pod-cleaner
   kubectl auth can-i create events --as=system:serviceaccount:kube-system:pod-cleaner
   ```

3. Check CronJob history:
   ```
   kubectl get jobs -n kube-system
   ```

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ stuck-pod-cleaner.yaml     # Standalone YAML for direct application
â”œâ”€â”€ docs/                      # Documentation assets
â”‚   â”œâ”€â”€ architecture.svg       # Architecture diagram
â”‚   â””â”€â”€ workflow.png           # Workflow diagram
â”œâ”€â”€ charts/                    # Helm chart directory
â”‚   â””â”€â”€ stuck-pod-cleaner/
â”‚       â”œâ”€â”€ Chart.yaml         # Chart metadata
â”‚       â”œâ”€â”€ values.yaml        # Default configuration values
â”‚       â””â”€â”€ templates/         # Chart templates
â”‚           â”œâ”€â”€ cronjob.yaml   # Main CronJob definition
â”‚           â”œâ”€â”€ rbac.yaml      # RBAC resources
â”‚           â””â”€â”€ NOTES.txt      # Installation notes
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ custom-configuration.yaml
â”œâ”€â”€ CONTRIBUTING.md
â””â”€â”€ LICENSE
```

## ğŸ‘¥ Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.